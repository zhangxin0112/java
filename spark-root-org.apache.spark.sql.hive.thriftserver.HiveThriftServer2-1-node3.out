Spark Command: /usr/java/jdk1.8.0_66/bin/java -cp /opt/spark/spark-2.3.0-SNAPSHOT-bin-custom-spark/conf/:/opt/spark/spark-2.3.0-SNAPSHOT-bin-custom-spark/jars/*:/etc/hadoop/conf/ -Xmx1g -Dhdp.version=2.6.0-cdh5.7.0 org.apache.spark.deploy.SparkSubmit --class org.apache.spark.sql.hive.thriftserver.HiveThriftServer2 --name Thrift JDBC/ODBC Server spark-internal
========================================
17/11/01 13:31:28 WARN JobConf: The variable mapred.child.ulimit is no longer used.
17/11/01 13:31:29 WARN JobConf: The variable mapred.child.ulimit is no longer used.
17/11/01 13:31:30 WARN JobConf: The variable mapred.child.ulimit is no longer used.
17/11/01 13:31:34 WARN JobConf: The variable mapred.child.ulimit is no longer used.
17/11/01 13:31:35 WARN JobConf: The variable mapred.child.ulimit is no longer used.
17/11/01 13:31:36 WARN JobConf: The variable mapred.child.ulimit is no longer used.
17/11/01 13:31:38 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
17/11/01 13:31:39 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
17/11/01 13:31:53 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
17/11/01 13:31:53 WARN JobConf: The variable mapred.child.ulimit is no longer used.
17/11/01 13:31:58 WARN JobConf: The variable mapred.child.ulimit is no longer used.
17/11/01 13:31:58 WARN JobConf: The variable mapred.child.ulimit is no longer used.
17/11/01 13:31:59 WARN JobConf: The variable mapred.child.ulimit is no longer used.
17/11/01 13:32:01 WARN JobConf: The variable mapred.child.ulimit is no longer used.
SLF4J: Failed to load class "org.slf4j.impl.StaticLoggerBinder".
SLF4J: Defaulting to no-operation (NOP) logger implementation
SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.
17/11/01 13:32:02 WARN log: Updating partition stats fast for: test_e
17/11/01 13:32:02 WARN log: Updated size to 209
17/11/01 13:32:08 WARN JobConf: The variable mapred.child.ulimit is no longer used.
17/11/01 13:32:21 WARN JobConf: The variable mapred.child.ulimit is no longer used.
17/11/01 13:32:21 WARN JobConf: The variable mapred.child.ulimit is no longer used.
17/11/01 13:32:21 WARN JobConf: The variable mapred.child.ulimit is no longer used.
17/11/01 13:32:22 WARN JobConf: The variable mapred.child.ulimit is no longer used.
17/11/01 13:32:22 ERROR SparkExecuteStatementOperation: Error executing query, currentState RUNNING, 
org.apache.spark.sql.AnalysisException: org.apache.hadoop.hive.ql.metadata.HiveException: Unable to move source hdfs://ns/user/hive/warehouse/test_e/.hive-staging_hive_2017-11-01_13-32-21_589_2836439078234128529-2/-ext-10000/part-00000-b21f95e1-788c-409c-a6f0-59909ab15e73-c000 to destination hdfs://ns/user/hive/warehouse/test_e/pt=1/part-00000-b21f95e1-788c-409c-a6f0-59909ab15e73-c000;
	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:106)
	at org.apache.spark.sql.hive.HiveExternalCatalog.loadPartition(HiveExternalCatalog.scala:833)
	at org.apache.spark.sql.hive.execution.InsertIntoHiveTable.run(InsertIntoHiveTable.scala:216)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:70)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:68)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:79)
	at org.apache.spark.sql.Dataset$$anonfun$6.apply(Dataset.scala:186)
	at org.apache.spark.sql.Dataset$$anonfun$6.apply(Dataset.scala:186)
	at org.apache.spark.sql.Dataset$$anonfun$49.apply(Dataset.scala:3112)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:77)
	at org.apache.spark.sql.Dataset.withAction(Dataset.scala:3111)
	at org.apache.spark.sql.Dataset.<init>(Dataset.scala:186)
	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:71)
	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:638)
	at org.apache.spark.sql.SQLContext.sql(SQLContext.scala:694)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:231)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$1$$anon$2.run(SparkExecuteStatementOperation.scala:174)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$1$$anon$2.run(SparkExecuteStatementOperation.scala:171)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1692)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$1.run(SparkExecuteStatementOperation.scala:184)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: Unable to move source hdfs://ns/user/hive/warehouse/test_e/.hive-staging_hive_2017-11-01_13-32-21_589_2836439078234128529-2/-ext-10000/part-00000-b21f95e1-788c-409c-a6f0-59909ab15e73-c000 to destination hdfs://ns/user/hive/warehouse/test_e/pt=1/part-00000-b21f95e1-788c-409c-a6f0-59909ab15e73-c000
	at org.apache.hadoop.hive.ql.metadata.Hive.moveFile(Hive.java:2644)
	at org.apache.hadoop.hive.ql.metadata.Hive.copyFiles(Hive.java:2711)
	at org.apache.hadoop.hive.ql.metadata.Hive.loadPartition(Hive.java:1403)
	at org.apache.hadoop.hive.ql.metadata.Hive.loadPartition(Hive.java:1324)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.spark.sql.hive.client.Shim_v0_14.loadPartition(HiveShim.scala:829)
	at org.apache.spark.sql.hive.client.HiveClientImpl$$anonfun$loadPartition$1.apply$mcV$sp(HiveClientImpl.scala:736)
	at org.apache.spark.sql.hive.client.HiveClientImpl$$anonfun$loadPartition$1.apply(HiveClientImpl.scala:734)
	at org.apache.spark.sql.hive.client.HiveClientImpl$$anonfun$loadPartition$1.apply(HiveClientImpl.scala:734)
	at org.apache.spark.sql.hive.client.HiveClientImpl$$anonfun$withHiveState$1.apply(HiveClientImpl.scala:273)
	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:211)
	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:210)
	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:256)
	at org.apache.spark.sql.hive.client.HiveClientImpl.loadPartition(HiveClientImpl.scala:734)
	at org.apache.spark.sql.hive.HiveExternalCatalog$$anonfun$loadPartition$1.apply$mcV$sp(HiveExternalCatalog.scala:845)
	at org.apache.spark.sql.hive.HiveExternalCatalog$$anonfun$loadPartition$1.apply(HiveExternalCatalog.scala:833)
	at org.apache.spark.sql.hive.HiveExternalCatalog$$anonfun$loadPartition$1.apply(HiveExternalCatalog.scala:833)
	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:97)
	... 26 more
Caused by: java.io.IOException: Filesystem closed
	at org.apache.hadoop.hdfs.DFSClient.checkOpen(DFSClient.java:798)
	at org.apache.hadoop.hdfs.DFSClient.getEZForPath(DFSClient.java:2966)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getEZForPath(DistributedFileSystem.java:1906)
	at org.apache.hadoop.hdfs.client.HdfsAdmin.getEncryptionZoneForPath(HdfsAdmin.java:262)
	at org.apache.hadoop.hive.shims.Hadoop23Shims$HdfsEncryptionShim.isPathEncrypted(Hadoop23Shims.java:1221)
	at org.apache.hadoop.hive.ql.metadata.Hive.moveFile(Hive.java:2607)
	... 46 more
17/11/01 13:32:22 ERROR SparkExecuteStatementOperation: Error running hive query: 
org.apache.hive.service.cli.HiveSQLException: org.apache.spark.sql.AnalysisException: org.apache.hadoop.hive.ql.metadata.HiveException: Unable to move source hdfs://ns/user/hive/warehouse/test_e/.hive-staging_hive_2017-11-01_13-32-21_589_2836439078234128529-2/-ext-10000/part-00000-b21f95e1-788c-409c-a6f0-59909ab15e73-c000 to destination hdfs://ns/user/hive/warehouse/test_e/pt=1/part-00000-b21f95e1-788c-409c-a6f0-59909ab15e73-c000;
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:268)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$1$$anon$2.run(SparkExecuteStatementOperation.scala:174)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$1$$anon$2.run(SparkExecuteStatementOperation.scala:171)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1692)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$1.run(SparkExecuteStatementOperation.scala:184)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
